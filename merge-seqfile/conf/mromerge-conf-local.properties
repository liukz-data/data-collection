# 用来配置 merge-seqfile 所需要的配置信息
# 此文件存放在HDFS上
###########################################################################
######################### CDH集群访问的 相关配置 #########################
# CDH 集群使用的安全策略，kerberos 或 simple
hadoop_security_authentication=kerberos
#hadoop_security_authentication=simple
# CDH 集群如果使用kerberos安全策略的话，kerberos的配置文件的位置
krb5_conf=/etc/krb5.conf
# 访问 CDH Hive 的用户、keytab文件位置
hive_user=mrdas@WY.CMDI.CMCC
hive_keytab=/home/mrdas/mrdas.keytab

#mromerge_conf_hdfs=/test/test_lkz_other/prop/lkz-test-mromerge-conf-v5.properties
mromerge_conf_hdfs=/mro/property/mromerge-conf-hdfs.properties

######################### Sequence Files 相关配置 #########################
# 位于HDFS上的某地市某日期某小时的所有SequenceFile 输出的根目录，其下设 /<city>/<date>/<hour> 三级子目录
seqfile_root=/mro/sf

# 位于HDFS上的comp_seqfiles目录用来存放名为 city-date-hour 格式的空文件，
# 用来表明 某地市某日期某小时的所有SequenceFile已完成输出、等待合并
# 根据这个配置，和seqfile_root的值一起拼成要合并的某地市某日期某小时的 SeqFile所在目录
#comp_seqfiles=/zhangyan/mro/comp_seqfiles
######################### Hive表相关配置 #########################
#  beeline 连接的用户字符串
beeline_user=jdbc:hive2://could004:10000/
beeline_principal=hive/could004@WY.CMDI.CMCC
# Hive中用来存放合并后的MRO数据的 数据库名
dbname=mro
# Hive中用来存放合并后的MRO数据的 表名、表文件存放路径
tb_name=mro_dt_rec
tb_location=/mro/mro_dt_rec
# Hive中用来存放合并后的MRO数据的 表 的压缩算法，默认为 "snappy"
tb_compress=snappy
# 描述日志的字段信息（作为构造Hive表的列的依据）文件所在位置
mroobj_json=/mro/property/mro_field.json
# Hive表中数据保留期限
data_valid_days=7
######################### 数据合并程序 产生的log的 相关配置 #########################
# merge-data.sh产生日志的目录
#log_dir=/home/mrdas/process/datacollection/logs
# Spark merge-seqfile的日志级别，可选值 ERROR、INFO、DEBUG、TRACE
log_level=INFO
# 日志数据库访问方式
# could008
pgdb_ip=10.254.222.226
pgdb_port=5432
pgdb_user=zhangyan
pgdb_passwd=kKRLVHNfR554Ihda6uHhRg==
pgdb_db=mlogdb

