# 用来配置 merge-seqfile 所需要的配置信息
# 此文件存放在HDFS上
###########################################################################
######################### CDH集群访问的 相关配置 #########################
# CDH 集群使用的安全策略，kerberos 或 simple
hadoop_security_authentication=kerberos
#hadoop_security_authentication=simple

# CDH 集群如果使用kerberos安全策略的话，kerberos的配置件的位置
krb5_conf=/etc/krb5.conf

# 访问 CDH Hive 的用户、keytab文件位置
#hive_user=mrdas@WY.CMDI.CMCC

hive_keytab=/home/mrdas/mrdas.keytab
######################### Sequence Files 相关配置 #########################
# 位于HDFS上的某地市某日期某小时的所有SequenceFile 输出的根目录，其下设 /<city>/<date>/<hour> 三级子目录
seqfile_root=/mro/sf

# 位于HDFS上的comp_seqfiles目录用来存放名为 city-date-hour 格式的空文件，
# 用来表明 某地市某日期某小时的所有SequenceFile已完成输出、等待合并
# 根据这个配置，和seqfile_root的值一起拼成要合并的某地市某日期某小时的 SeqFile所在目录
comp_seqfiles=/mro/comp_seqfiles

#merge完成以后输出文件到此目录，为下一步业务逻辑解析做准备
comp_merge=/mro/comp_merge

######################### Hive表相关配置 #########################
#  beeline 连接的用户字符串
beeline_user=jdbc:hive2://could004:10000/
beeline_principal=hive/could004@WY.CMDI.CMCC
# Hive中用来存放合并后的MRO数据的 数据库名
dbname=mro
#dbname=test_lkz
# Hive中用来存放合并后的MRO数据的 表名、表文件存放路径
tb_name=mro_dt_rec
tb_location=/mro/mro_dt_rec
# Hive中用来存放合并后的MRO数据的 表 的压缩算法，默认为 "snappy"
tb_compress=snappy
#tb_compress=zlib
# 描述日志的字段信息（作为构造Hive表的列的依据）文件所在位置
mroobj_json=/mro/property/mro_field.json
# Hive表中数据保留期限
data_valid_days=7
######################### 数据合并程序 产生的log的 相关配置 #########################
# merge-data.sh产生日志的目录
#log_dir=/home/mrdas/datacollection/logs/
# Spark merge-seqfile的日志级别，可选值 ERROR、INFO、DEBUG、TRACE
log_level=ERROR
# 日志数据库访问方式
# could008
pgdb_ip=10.254.222.226
pgdb_port=5432
pgdb_user=zhangyan
pgdb_passwd=kKRLVHNfR554Ihda6uHhRg==
pgdb_db=mlogdb


# 配置hive表分区内每一个文件大小，单位M
tb_region_file_size=192

# 最小切片大小，最大切片大小，单位b，这里是64m，128m
mapreduce.input.fileinputformat.split.minsize=67108864
mapreduce.input.fileinputformat.split.maxsize=100663296

# stage之间提交时间的间隔，目的是保证每个小时数据顺序执行,单位s,算法：延迟时间=0*5，1*5，3*5，10*5

stage_delay_submit_time=3

